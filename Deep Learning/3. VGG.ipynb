{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras.utils as image\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_data(df):\n",
    "    image_data = []\n",
    "    img_paths = np.asarray(df.iloc[:, 0])\n",
    "    \n",
    "    for i in tqdm(range(len(img_paths))):\n",
    "        img = image.load_img(img_paths[i],target_size=(200, 150, 3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        image_data.append(img)   \n",
    "        \n",
    "    X = np.array(image_data)\n",
    "    Y = np.array(df.iloc[:,1:29])\n",
    "    \n",
    "    print(\"Shape of images:\", X.shape)\n",
    "    print(\"Shape of labels:\", Y.shape)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing train..\")\n",
    "train_df = pd.read_csv(\"CSV/Train.csv\", delimiter=\" \")\n",
    "X_train, Y_train = arrange_data (train_df)\n",
    "\n",
    "print(\"Processing valid..\")\n",
    "val_df = pd.read_csv(\"CSV/Valid.csv\", delimiter=\" \")\n",
    "X_val, Y_val = arrange_data (val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "num_classes = 28 \n",
    "\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(200, 150, 3))\n",
    "\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(vgg_conv)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "    EPOCHS = 50\n",
    "    BS = 64\n",
    "    history = model.fit(aug.flow(X_train, Y_train, batch_size=BS), validation_data=(X_val, Y_val), steps_per_epoch=len(X_train) // BS, epochs=EPOCHS)\n",
    "    model.save('Model_VGG.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
